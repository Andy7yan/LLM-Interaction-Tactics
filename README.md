# LLM Interaction Tactics
### Workflows for Overcoming Model Constraints

---

## ðŸ“– Manifesto

> "Just as programmers must master programming languages, senior AI workers must master the language of AIâ€”Natural Language."

This repository is not merely a collection of prompts; it is an archive of **AI Literacy** and empirical research into human-AI interaction.

The core philosophy here is **Language as Code**. By treating natural language with the same rigorous structure as software code, we can "orchestrate" the cognitive processes of Large Language Models (LLMs). However, current models are not omnipotent; they are bound by constraints such as token limits, reasoning instability, and memory interference.

This repository provides a set of **"Tactics"**â€”practical, heuristic strategies designed to navigate these bounds (Bounded Intelligence). By employing structured prompts and engineering-grade workflows, we can mitigate model limitations and achieve high-fidelity outputs.

---

## ðŸŽ¯ Methodology: Tactics for Constraints

These tactics are derived from observing specific model behaviors and limitations:

* **Constraint: Context Window Limits & "Lost in the Middle"**
    * **Tactic: Recursive Search Strategy.**
        Instead of overloading a single chat window, use a depth-first search (DFS) approach. When encountering complex or unknown concepts, open a new, parallel window to query the specific term. Once the concept is mastered, "return" to the main thread. This method mathematically functions like Bayesian optimization, efficiently finding entry points into new conceptual spaces[cite: 1].
    * **Tactic: Problem Decomposition.**
        Complex problems must be broken down. Do not force the model to solve everything in one turn. Instruct the model to analyze the prompt first, then generate the solution in steps[cite: 1].

* **Constraint: Hallucination & Reasoning Flaws**
    * **Tactic: Explicit Verification.**
        Models struggle to self-correct implicitly. You must explicitly instruct the model to assess the situation and verify its reasoning against established sources for factual tasks, while omitting this for creative tasks to prioritize flow[cite: 15].
    * **Tactic: Human-in-the-Loop Weighting.**
        User input carries higher weight than the model's self-generated history. For critical project constraints, explicitly re-inject the core requirements to prevent them from being "diluted" by the conversation history[cite: 1].

* **Constraint: Identity & Context Confusion**
    * **Tactic: Persona/Context Separation.**
        Strictly distinguish between **Gem Personas** (Task-Specific Expert Roles) and **Personal Context** (General User Data). Never assign a fixed global persona for general interactions; instead, use conditional logic to trigger specific memories only when relevant[cite: 3, 6, 7].

---

## ðŸ“‚ Repository Structure

This project follows a modular architecture, treating prompts as reusable code components.

```text
LLM-Interaction-Tactics/
â”œâ”€â”€ README.md                  # Project Index & Manifesto
â”œâ”€â”€ tactics/                   # [The Playbook] Workflows & Heuristics
â”‚   â”œâ”€â”€ recursive-search.md    # The DFS approach to knowledge acquisition
â”‚   â”œâ”€â”€ parallel-windows.md    # Multi-threading for cognitive tasks
â”‚   â””â”€â”€ steering-basics.md     # Persona definition & Adjective modifiers
â”œâ”€â”€ prompt-library/            # [The Arsenal] Modular Prompt Files
â”‚   â”œâ”€â”€ meta/                  # Meta-Tools (Prompts that write prompts)
â”‚   â”‚   â””â”€â”€ instruction4instruction.md
â”‚   â”œâ”€â”€ academic/              # Research & Deep Reading
â”‚   â”‚   â”œâ”€â”€ paper-reader-stem.md
â”‚   â”‚   â””â”€â”€ knowledge-structuraliser.md
â”‚   â”œâ”€â”€ coding/                # Programming Assistance
â”‚   â”‚   â””â”€â”€ programming-entities.md
â”‚   â””â”€â”€ tutors/                # Domain-Specific Tutors
â”‚       â””â”€â”€ comp9313-tutor.md
â””â”€â”€ insights/                  # [The Theory] Notes on AI Literacy
    â””â”€â”€ language-as-code.md    # Natural Language as an engineering interface
